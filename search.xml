<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>南航航班数据爬虫</title>
      <link href="/2020/03/06/nan-hang-hang-ban-shu-ju-pa-chong/"/>
      <url>/2020/03/06/nan-hang-hang-ban-shu-ju-pa-chong/</url>
      
        <content type="html"><![CDATA[<h2 id="FlightAware网站上南航航班数据自动爬取"><a href="#FlightAware网站上南航航班数据自动爬取" class="headerlink" title="FlightAware网站上南航航班数据自动爬取"></a>FlightAware网站上南航航班数据自动爬取</h2><pre><code class="python">import pandas as pdfrom bs4 import BeautifulSoupimport numpy as npfrom selenium import webdriverfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.common.keys import Keysimport datetime#from selenium.webdriver.chrome.options import Optionsdef wait_load(Xpath):    #等待加载    locator = (By.XPATH,Xpath)    WebDriverWait(driver,20,0.5).until(EC.visibility_of_element_located(locator))def readtable():    html = driver.page_source    cur_page = BeautifulSoup(html,features=&quot;lxml&quot;)    cur_table = cur_page.find(&quot;table&quot;,{&quot;class&quot;:&quot;prettyTable fullWidth&quot;})    cur_tbody = cur_table.find(&quot;tbody&quot;)    cur_trs = cur_tbody.findAll(&quot;tr&quot;)    table = [[j for j in i.findAll(&quot;td&quot;)] for i in cur_trs]    n,m = np.array(table).shapes    result = [[table[i][j].getText() for j in range(m)] for i in range(n)]    result = [[j.replace(&quot;\n&quot;,&quot;&quot;).replace(&quot; &quot;,&quot;&quot;) for j in i] for i in result]    result = pd.DataFrame(result)    result.columns = &#39;标识符 机型 始发地 目的地 出发 预计到达时间&#39;.split(&quot; &quot;)    return resultif __name__ == &quot;__main__&quot;:    driver = webdriver.PhantomJS(r&quot;.\phantomjs-2.1.1-windows\bin\phantomjs.exe&quot;)#    options = Options()#    options.add_argument(&#39;--headless&#39;)#    driver = webdriver.Chrome(executable_path=r&quot;C:\Program Files (x86)\Google\Chrome\Application\chromedriver.exe&quot;,options=options)    driver.get(&quot;https://zh.flightaware.com/live/fleet/&quot;)    wait_load(&#39;//*[@id=&quot;topWrapper&quot;]/div[1]/nav/div/div[2]/a&#39;)    login_in = driver.find_element_by_xpath(&#39;//*[@id=&quot;topWrapper&quot;]/div[1]/nav/div/div[2]/a&#39;)    login_in.click()    wait_load(&#39;//*[@id=&quot;popupLogin&quot;]/div/div[2]/div/form/div[1]/input[1]&#39;)    driver.find_element_by_name(&quot;flightaware_username&quot;).send_keys(&quot;&quot;)    driver.find_element_by_name(&quot;flightaware_password&quot;).send_keys(&quot;&quot;)    driver.find_element_by_class_name(&quot;actionButton&quot;).click()    wait_load(&#39;//*[@id=&quot;slideOutPanel&quot;]/div/table[2]/tbody&#39;)    print(&#39;登录成功&#39;)    driver.get(&quot;https://zh.flightaware.com/live/fleet/CSN&quot;)    wait_load(&#39;//*[@id=&quot;slideOutPanel&quot;]/div/table[2]/tbody/tr[2]/td/table/tbody&#39;)    results = readtable()    print(&#39;开始爬取数据&#39;)    while 1:        page_item = driver.find_element_by_xpath(&#39;//*[@id=&quot;slideOutPanel&quot;]/div/table[2]/tbody/tr[2]/td/span[2]&#39;)        try:            next_btn = page_item.find_element_by_link_text(&#39;后40条&#39;)        except:            try:                pre_btn = page_item.find_element_by_link_text(&#39;前40条&#39;)                print(&#39;完成&#39;)                break            except:                print(&quot;页面异常或航班数据少于40，仅有一个页面&quot;)                break        driver.execute_script(&quot;arguments[0].scrollIntoView();&quot;,next_btn)        next_btn.click()        wait_load(&#39;//*[@id=&quot;slideOutPanel&quot;]/div/table[2]/tbody/tr[2]/td/table/tbody&#39;)        result = readtable()        results = results.append(result)    results.index = range(len(results))    filename = datetime.datetime.now().strftime(&quot;%Y-%m-%d&quot;)+&quot;.xlsx&quot;    writer = pd.ExcelWriter(filename)    results.to_excel(writer, sheet_name=&#39;CSN&#39;)    writer.save()    writer.close()    driver.close()</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> selenium </tag>
            
            <tag> BeautifulSoup </tag>
            
            <tag> 爬虫 </tag>
            
            <tag> 南航 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的第一篇博文</title>
      <link href="/2020/02/20/wo-de-di-yi-pian-bo-wen/"/>
      <url>/2020/02/20/wo-de-di-yi-pian-bo-wen/</url>
      
        <content type="html"><![CDATA[<h2 id="用途说明"><a href="#用途说明" class="headerlink" title="用途说明"></a>用途说明</h2><p>目前，此博客网站用于总结个人学习经验，方便记录学习成果。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 声明 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
